MS_SL2_split_channelwise_model(
  (encoder_1d): Conv1D(1, 512, kernel_size=(16,), stride=(8,))
  (ln): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (proj): Conv1D(512, 128, kernel_size=(1,), stride=(1,))
  (slices): Sequential(
    (0): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (1): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (2): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
  )
  (PRelu): PReLU(num_parameters=1)
  (mask): Conv1D(128, 1024, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(512, 1, kernel_size=(16,), stride=(8,))
)
ConvTasNet #param: 5.05
input size torch.Size([16, 1000])
2
after encoder size torch.Size([16, 512, 124])
after LayerNorm and 1x1 Conv torch.Size([16, 128, 124])
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
 Out put of TcnResult shape torch.Size([16, 128, 124])
Output of Tcn size after pRelu torch.Size([16, 128, 124])
dimension of mask (tensor([[[-1.3243,  0.4044,  0.5281,  ...,  2.3300,  2.9040,  6.3179],
         [-3.1995, -5.3540, -3.4408,  ..., -8.7281, -5.1865, -5.0377],
         [-5.7205, -3.4412, -7.5596,  ..., -5.1333, -5.1582, -4.8533],
         ...,
         [-5.2577, -4.2026, -0.7618,  ..., -2.2134, -1.9108, -1.7769],
         [ 3.4701,  3.6582,  5.7375,  ...,  7.4240,  9.7309,  6.6495],
         [ 4.2707,  4.6580,  3.6418,  ..., -2.1654,  0.6537,  0.7286]],

        [[-1.6992, -1.9937,  0.0883,  ...,  3.5213,  5.3400,  5.7238],
         [-4.0969, -5.1090, -3.3312,  ..., -9.0030, -7.1081, -8.8985],
         [-3.2487, -4.3071, -7.8804,  ..., -4.0949, -5.8745, -5.2372],
         ...,
         [-2.9296, -2.3166, -2.6752,  ..., -2.6195, -1.9094, -0.3230],
         [ 1.0413,  1.2078,  4.5522,  ...,  6.0345,  7.3340,  7.2361],
         [ 2.8512,  3.8626,  2.4505,  ...,  1.1492,  0.8322,  0.7685]],

        [[ 0.4705, -1.8543, -1.0358,  ...,  1.7131,  2.5649,  5.5013],
         [-2.3593, -0.4863, -4.8474,  ..., -7.6546, -3.6008, -8.4670],
         [-4.1036, -4.9350, -5.4647,  ..., -2.8689, -7.0719, -2.5957],
         ...,
         [-2.5545, -5.7821, -5.1727,  ..., -1.8569, -2.3640, -0.1507],
         [ 2.6812,  5.6504,  5.5761,  ...,  6.0280,  6.6082,  7.5356],
         [ 5.4145,  3.1767,  4.6202,  ..., -0.4836,  0.4325,  3.5881]],

        ...,

        [[-0.3904, -3.7365, -3.6739,  ...,  4.2402,  3.6959,  5.0868],
         [-3.0938, -4.6897, -4.0191,  ..., -5.8517, -8.1894, -8.1191],
         [-5.4443, -5.8914, -4.7134,  ..., -5.1433, -2.7498, -5.1336],
         ...,
         [-4.8653, -3.8768, -4.8778,  ..., -0.1149, -0.9289,  0.6178],
         [ 2.6474,  4.3095,  4.7961,  ...,  4.1255,  5.2059,  6.6023],
         [ 3.0768,  1.9286,  2.8423,  ...,  1.4954,  3.0883, -0.2962]],

        [[-2.5441, -0.1503, -3.9984,  ...,  4.2316,  2.8801,  5.2636],
         [-2.8718, -4.2134, -4.7817,  ..., -6.0647, -9.2228, -5.6837],
         [-3.4849, -5.6151, -4.2754,  ..., -3.6333, -4.1043, -3.4971],
         ...,
         [-4.7647, -3.2804, -1.9768,  ..., -3.6722, -1.7690,  0.7586],
         [ 4.1151,  1.9624,  3.3761,  ...,  7.9364,  5.3646,  5.6588],
         [ 4.2997,  2.6204,  4.2091,  ...,  0.0721,  0.1659,  1.3346]],

        [[-0.6482, -1.3187, -1.1859,  ...,  3.1353,  2.5725,  5.2380],
         [-2.8621, -4.4319, -4.2210,  ..., -7.8010, -8.2678, -6.1254],
         [-5.5575, -5.7990, -6.0044,  ..., -2.6760, -3.1056, -4.8003],
         ...,
         [-3.8151, -3.2701, -1.5091,  ..., -2.1958,  1.3466,  1.3497],
         [ 1.8844,  2.2989,  2.8284,  ...,  7.5075,  5.4802,  5.0470],
         [ 3.4052,  4.1794,  4.1719,  ...,  0.7383,  0.7442,  0.3850]]],
       grad_fn=<SplitBackward0>), tensor([[[ 6.9872e-01,  2.0416e+00,  2.9183e+00,  ...,  1.5976e+00,
           7.1049e+00,  1.9779e+00],
         [ 8.0940e+00,  7.7129e+00,  7.0601e+00,  ...,  2.7597e+00,
           3.5385e-03,  3.3601e+00],
         [ 1.9946e-01,  2.8427e+00,  8.5972e-01,  ..., -3.5273e-01,
           1.3020e+00,  1.7697e+00],
         ...,
         [-1.6648e+00,  2.6746e-01, -1.4523e-01,  ..., -4.5830e-01,
           2.0496e+00,  1.6810e+00],
         [-3.2847e+00, -3.2684e+00, -1.5921e+00,  ..., -3.3195e+00,
          -3.4292e+00, -5.9083e+00],
         [ 1.2552e-01,  1.8252e+00,  3.1480e+00,  ...,  1.3541e+00,
           2.1532e-01,  3.7317e-01]],

        [[-2.1435e+00,  1.2232e+00,  1.7652e+00,  ...,  4.1779e+00,
           5.0570e+00,  3.4060e+00],
         [ 4.5043e+00,  6.0301e+00,  1.8629e+00,  ...,  2.5935e+00,
           3.2919e+00,  2.0440e+00],
         [ 9.5246e-01,  1.1123e+00,  7.6148e-01,  ...,  2.9849e+00,
           1.2050e+00,  1.6300e+00],
         ...,
         [ 1.2140e+00,  2.0730e+00,  1.8055e-03,  ...,  2.4868e+00,
           9.5752e-01, -1.9421e-01],
         [-3.4171e+00, -8.2907e-01, -5.8403e-01,  ..., -1.7491e+00,
          -2.4889e+00, -1.6144e+00],
         [-1.2062e+00, -1.2482e-01,  2.5767e+00,  ..., -2.8735e+00,
          -2.1221e+00, -6.9782e-01]],

        [[-3.6974e-01,  2.2684e+00,  1.2555e+00,  ...,  3.0484e+00,
           4.9688e+00,  2.1724e+00],
         [ 7.0031e+00,  5.7545e+00,  6.2060e+00,  ...,  4.1704e+00,
           2.2449e+00,  4.6154e-01],
         [-4.9171e-01,  1.2043e+00,  1.4366e+00,  ...,  7.2583e-02,
           6.8660e-01,  1.6174e+00],
         ...,
         [-2.9770e-01,  2.1227e+00,  1.3081e+00,  ...,  2.9309e+00,
           2.4426e-01,  1.4464e+00],
         [-6.4451e-01, -1.5926e+00, -4.1251e-01,  ..., -8.5230e-01,
          -1.8769e+00, -3.1607e+00],
         [-8.9394e-01,  8.3358e-01,  1.9866e+00,  ..., -8.2867e-01,
           1.0957e+00, -1.0914e+00]],

        ...,

        [[-4.3530e-01, -1.5848e+00,  2.7338e+00,  ...,  1.4479e+00,
           2.3991e+00,  4.0655e+00],
         [ 5.9833e+00,  5.0265e+00,  6.5286e+00,  ...,  3.9778e+00,
           2.4764e+00,  1.3052e+00],
         [-2.2448e+00,  8.0004e-01,  2.8071e+00,  ...,  6.0950e-01,
           2.5196e-01,  7.0969e-02],
         ...,
         [ 6.9965e-02,  6.5338e-01,  3.3815e+00,  ..., -1.0328e+00,
           1.9132e+00,  2.8205e+00],
         [-3.1385e+00, -1.8491e+00,  1.3355e+00,  ..., -2.4196e+00,
          -1.2103e+00,  2.0535e+00],
         [-1.2148e+00,  2.9446e+00, -5.0429e-01,  ...,  2.5094e-01,
          -6.0809e-01,  2.8287e+00]],

        [[-4.5289e-02,  1.7167e-01,  2.4678e+00,  ...,  2.2602e+00,
           1.8580e+00,  3.1546e+00],
         [ 3.6107e+00,  6.2793e+00,  6.9900e+00,  ...,  1.3201e+00,
           1.8590e+00,  2.3409e+00],
         [-4.8669e-01,  9.4920e-01,  2.1710e+00,  ..., -1.5725e-01,
          -4.3678e-01, -8.9559e-01],
         ...,
         [ 1.3256e+00, -1.1713e+00,  1.7560e+00,  ...,  5.1799e-01,
           1.5638e+00,  3.2859e+00],
         [-1.6047e+00, -2.3896e+00,  3.9804e-01,  ..., -3.4550e-01,
          -1.9712e+00,  1.5507e-01],
         [ 4.8001e-01, -1.9607e-01,  2.5423e+00,  ...,  4.2003e-01,
          -5.6293e-01,  1.1941e+00]],

        [[ 1.5168e+00, -4.4583e-01, -1.4946e-01,  ...,  3.9479e+00,
           1.5940e+00,  3.0965e+00],
         [ 4.9395e+00,  5.4002e+00,  4.6227e+00,  ...,  2.3483e+00,
           2.1793e+00,  5.3753e+00],
         [ 3.1713e+00,  1.5055e+00,  2.7556e+00,  ..., -2.3708e-01,
          -1.1316e+00,  2.9387e+00],
         ...,
         [-1.0460e+00,  1.3274e+00,  6.5076e-01,  ...,  2.2099e+00,
           6.4714e-01,  2.8853e+00],
         [-2.6284e+00, -6.4813e-01, -2.1668e+00,  ..., -1.2515e+00,
          -1.1074e+00, -2.5217e+00],
         [-4.6814e-01,  1.3381e+00,  7.1673e-01,  ..., -1.9482e+00,
           5.7617e-04,  1.8577e+00]]], grad_fn=<SplitBackward0>))
after 1x1 Conv mask) torch.Size([16, 512, 124])
torch.Size([16, 1000])


*********************************************************************************


MS_SL2_split_channelwise_model(
  (encoder_1d): Conv1D(1, 512, kernel_size=(16,), stride=(8,))
  (ln): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (proj): Conv1D(512, 128, kernel_size=(1,), stride=(1,))
  (slices): Sequential(
    (0): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (1): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (2): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
  )
  (PRelu): PReLU(num_parameters=1)
  (mask): Conv1D(128, 1024, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(512, 1, kernel_size=(16,), stride=(8,))
)
ConvTasNet #param: 5.05
input size torch.Size([16, 1000])
2
after encoder size torch.Size([16, 512, 124])
after LayerNorm and 1x1 Conv torch.Size([16, 128, 124])
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
slice input size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
1D Conv block input size torch.Size([16, 128, 124])
1D blick after fist 1x1Conv size torch.Size([16, 512, 124])
1D Conv block after dconv size torch.Size([16, 512, 124])
finished 1D Conv block skip_connection size torch.Size([16, 128, 124])
finished 1D Conv block ouput size torch.Size([16, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 16
 Out put of TcnResult shape torch.Size([16, 128, 124])
Output of Tcn size after pRelu torch.Size([16, 128, 124])
dimension of mask (tensor([[[  5.6681,   3.4081,   3.8025,  ...,  -1.3462,   2.3895,  -0.7264],
         [  1.4437,   5.1394,   1.9551,  ...,   8.0564,   9.7765,   9.0361],
         [ -0.5816,  -5.3744,  -5.1838,  ...,  -3.0577,  -5.8599,  -2.9759],
         ...,
         [ -2.4731,  -6.1825,  -4.4055,  ...,  -4.8339,  -7.2644,  -6.0383],
         [  0.2038,  -0.1182,  -2.5165,  ...,  -5.0005,  -3.8725, -10.0820],
         [ -0.6499,  -7.2853,  -8.0348,  ...,  -6.5844,  -4.1081, -10.2193]],

        [[  3.5473,   3.1690,   2.7011,  ...,  -1.1479,   0.3849,  -0.3790],
         [  3.6790,   5.6254,   3.6240,  ...,  10.7534,  10.1476,   8.7262],
         [ -1.1784,  -4.4893,  -5.9260,  ...,  -3.5200,  -1.4222,  -0.6945],
         ...,
         [ -2.9794,  -5.3199,  -6.3929,  ...,  -4.8119,  -6.9310,  -7.5312],
         [  1.0804,  -3.4152,  -4.4191,  ...,  -3.4400,  -1.7370,  -3.7307],
         [ -7.6386,  -6.5550,  -3.6991,  ...,  -8.4524,  -1.3090,  -6.2156]],

        [[  2.9692,  -1.2030,   3.6438,  ...,   2.9195,   1.4230,   2.5579],
         [ -0.0750,   5.6861,   3.2114,  ...,   5.6191,   4.8966,   7.2277],
         [ -2.1302,  -3.0693,  -4.6442,  ...,  -2.3867,  -3.7554,  -5.0081],
         ...,
         [ -2.5393,  -3.6355,  -6.4792,  ...,  -3.3120,  -5.3867,  -2.5484],
         [ -2.6125,  -0.7112,  -5.1392,  ...,  -2.5964,  -2.1977,  -2.3550],
         [ -8.8145,  -8.2814,  -7.0443,  ...,  -7.4878,  -5.3013,  -6.4147]],

        ...,

        [[  0.5797,   2.3427,   2.8202,  ...,   0.7205,   2.8142,   1.1461],
         [  4.4613,   3.6255,   7.9291,  ...,   8.5554,   7.4065,   6.6530],
         [ -1.6020,  -3.9294,  -5.9449,  ...,  -5.9842,  -4.1360,  -6.3256],
         ...,
         [ -4.2999,  -3.1535,  -7.0506,  ...,  -5.9452,  -9.2162,  -6.3093],
         [ -1.9403,  -1.0262,   1.0586,  ...,  -4.1113,  -2.0844,  -2.0364],
         [ -7.0345,  -2.0219,  -5.9648,  ...,  -8.3880,  -5.0008,  -5.3767]],

        [[  5.7326,   3.3873,   0.7640,  ...,   3.0532,   5.0228,   0.3893],
         [  4.4185,   0.5668,   4.8343,  ...,   5.2463,   8.5808,   7.6074],
         [ -1.6109,  -4.4984,  -1.6621,  ...,  -5.3311,  -3.8724,  -4.4727],
         ...,
         [ -4.7196,  -1.9430,  -3.0854,  ...,  -7.3387,  -3.7594,  -7.9962],
         [ -3.5249,   0.1287,  -0.5981,  ...,  -1.5669,  -7.6564,  -5.0971],
         [ -5.9020,  -5.4744,  -2.5711,  ...,  -5.0818,  -5.6669,  -6.7841]],

        [[  4.7448,   4.1723,   2.2322,  ...,   0.5127,   0.3879,   2.3485],
         [  0.3743,   4.0190,   3.3100,  ...,   9.5076,   6.5566,  10.4081],
         [ -0.7679,  -7.4197,  -0.1854,  ...,  -3.9485,  -5.7300,  -2.8885],
         ...,
         [ -5.4712,  -3.1748,  -7.4175,  ...,  -4.0068,  -3.5656,  -2.4487],
         [  0.8835,   1.1095,   0.3129,  ...,  -5.8156,  -3.8391,  -5.3977],
         [ -8.7694,  -5.4673,  -8.6426,  ...,  -5.7788,  -7.1225,  -4.3505]]],
       grad_fn=<SplitBackward0>), tensor([[[ 4.8316,  6.3068,  4.6071,  ...,  8.3431,  8.0538,  5.0012],
         [-0.7834, -0.2399, -1.5155,  ...,  4.2515,  2.5987,  3.7822],
         [-2.1364, -1.0874, -3.4954,  ..., -4.1731, -7.4577, -4.0756],
         ...,
         [ 3.6980,  3.3039,  2.3197,  ...,  5.8869, 15.9156,  8.8164],
         [ 0.7540, -2.9113, -0.5912,  ...,  1.5606,  2.7644,  0.5210],
         [-1.5828, -2.0459,  2.2728,  ..., -0.5640, -3.3577,  2.3374]],

        [[ 3.7390,  5.0460,  6.0906,  ...,  5.0729,  7.5757,  5.7321],
         [ 0.7613,  1.1071, -1.1638,  ...,  1.7389,  0.8451,  4.7733],
         [-5.3958, -7.7237, -6.4309,  ..., -8.8620, -3.3378, -5.0326],
         ...,
         [ 6.6604,  7.9581,  6.3000,  ...,  9.1711, 10.8966, 11.3545],
         [ 4.7375, -3.4042,  1.7215,  ..., -0.4868,  3.5495,  3.8233],
         [-2.5389, -3.8252, -0.6922,  ..., -1.2750, -2.2675, -1.3332]],

        [[ 5.9847,  9.1463,  4.9180,  ...,  5.2196,  1.9425, -2.2704],
         [-0.2663, -1.8096,  1.4992,  ...,  2.7542,  4.2638,  0.9455],
         [-2.1566, -4.1955, -3.5711,  ..., -3.0346, -4.5259, -3.5891],
         ...,
         [ 4.2590,  1.3145,  3.8602,  ...,  6.8314, 12.6496,  4.2499],
         [ 5.4295, -1.1128,  0.4876,  ...,  2.0327, -1.0895,  0.9076],
         [-1.7827, -1.8890, -2.6938,  ...,  1.9444,  3.4376, -1.1470]],

        ...,

        [[ 5.7152,  8.1406,  3.6391,  ...,  4.7883,  6.9462,  6.0345],
         [-0.0347,  0.8893, -4.3072,  ...,  2.9715,  3.8942,  2.8186],
         [-3.7064, -5.6422, -3.1966,  ..., -6.7227, -4.2527, -4.6751],
         ...,
         [ 4.1878,  3.8734,  6.7163,  ...,  9.6579, 11.5659,  8.9018],
         [ 1.8915,  0.9180,  2.2343,  ...,  3.5383,  2.7866,  1.0561],
         [-2.8123, -3.4710, -1.4781,  ..., -0.9999, -1.8629, -1.6231]],

        [[ 8.2210,  6.7836,  4.7039,  ...,  4.0858,  3.4156,  4.1309],
         [-0.7128,  1.6227,  0.7770,  ...,  0.5147,  4.8604,  1.5233],
         [-4.6340,  0.7145, -7.1719,  ..., -6.5479, -6.0461, -0.5988],
         ...,
         [ 3.5650, -0.4521,  3.7340,  ...,  5.8920, 11.2404,  7.0567],
         [ 0.7101,  2.7338,  1.3019,  ...,  2.1344,  4.0612,  2.7422],
         [ 2.1646,  1.4516, -1.2236,  ..., -0.7334, -6.1509, -1.7168]],

        [[ 6.4964,  6.6802,  7.7525,  ...,  4.8767,  5.0748,  2.8966],
         [-1.3259, -4.4847, -4.6623,  ...,  3.7436,  3.7560,  6.2563],
         [-3.1510, -3.3322, -5.0529,  ..., -6.4808, -5.5751, -4.0116],
         ...,
         [ 4.6977,  4.3896,  2.2897,  ..., 11.2612, 10.1936,  8.9241],
         [ 3.8307,  0.8070,  0.0900,  ...,  5.8974,  2.6054,  5.8565],
         [-0.5575, -2.9551,  0.4395,  ..., -0.2349,  3.2185, -5.9564]]],
       grad_fn=<SplitBackward0>))
after 1x1 Conv mask) torch.Size([16, 512, 124])
torch.Size([16, 1000])

*******************************************************************************

MS_SL2_split_channelwise_model(
  (encoder_1d): Conv1D(1, 512, kernel_size=(16,), stride=(8,))
  (ln): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (proj): Conv1D(512, 128, kernel_size=(1,), stride=(1,))
  (slices): Sequential(
    (0): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (1): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (2): Sequential(
      (0): Sequential(
        (0): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (2): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (3): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (4): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (5): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (6): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
        (7): Conv1DBlock(
          (conv1x1): Conv1D(128, 512, kernel_size=(1,), stride=(1,))
          (prelu1): PReLU(num_parameters=1)
          (lnorm1): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
          (prelu2): PReLU(num_parameters=1)
          (lnorm2): ChannelWiseLayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (sconv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
          (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
  )
  (PRelu): PReLU(num_parameters=1)
  (mask): Conv1D(128, 1024, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(512, 1, kernel_size=(16,), stride=(8,))
)
ConvTasNet #param: 5.05
input size torch.Size([8, 1000])
2
after encoder size torch.Size([8, 512, 124])
after LayerNorm and 1x1 Conv torch.Size([8, 128, 124])
slice input size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
slice input size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
slice input size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
1D Conv block input size torch.Size([8, 128, 124])
1D blick after fist 1x1Conv size torch.Size([8, 512, 124])
1D Conv block after dconv size torch.Size([8, 512, 124])
finished 1D Conv block skip_connection size torch.Size([8, 128, 124])
finished 1D Conv block ouput size torch.Size([8, 128, 124])
Weight value1 tensor(0.5010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.3990, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
Weight value1 tensor(0.4010, grad_fn=<SelectBackward0>)
lenght of skip connection TCN : 8
 Out put of TcnResult shape torch.Size([8, 128, 124])
Output of Tcn size after pRelu torch.Size([8, 128, 124])
dimension of mask (tensor([[[ 3.0020,  2.1646,  2.3117,  ...,  0.6607, -1.7399,  0.6103],
         [ 2.0596,  2.0056,  2.6213,  ...,  3.3787,  4.4408,  6.3688],
         [-2.0117,  1.3697, -0.2095,  ...,  0.6661, -1.9017, -3.0483],
         ...,
         [ 1.6816,  0.0390, -3.3959,  ...,  1.5326,  2.5189,  5.7911],
         [-4.4320, -0.4326, -0.9682,  ..., -2.4480,  0.8979, -1.7269],
         [ 5.5299,  8.2336,  7.6523,  ..., -2.8961,  1.6886,  2.2922]],

        [[ 5.1795,  2.7499,  1.1969,  ...,  2.1631,  0.8428, -1.0172],
         [ 0.2862, -0.8363,  0.2610,  ...,  4.5790,  5.2940,  4.1545],
         [-1.1574,  3.6795, -2.2440,  ..., -4.3888, -3.8177, -1.4380],
         ...,
         [-2.4950,  0.6561,  3.4241,  ...,  3.5158, -0.4987,  3.9293],
         [-1.5163, -3.4265, -2.1613,  ..., -1.8098, -0.6140, -3.7495],
         [ 8.8955,  6.7152,  7.4741,  ...,  1.2378, -0.5485,  2.0727]],

        [[ 4.8748, -3.9280,  1.5973,  ..., -4.0380, -3.3604, -0.1725],
         [-0.9265,  1.4002,  0.3047,  ...,  2.6798,  5.1158,  3.0056],
         [ 1.1040, -0.2297, -1.4526,  ..., -3.0726, -1.8285, -0.8913],
         ...,
         [ 1.5658,  0.6993,  2.8528,  ...,  5.8321,  2.5289,  5.1057],
         [-6.8348, -2.9777, -3.5386,  ..., -5.1202, -0.0442, -2.5631],
         [ 7.7202,  7.9246,  3.5126,  ...,  3.0391,  1.8006,  0.4306]],

        ...,

        [[ 4.8393,  0.3185,  1.0310,  ..., -0.2691,  2.5639, -0.4930],
         [-0.6012,  1.6246,  1.0305,  ...,  8.1370,  7.1137,  5.8461],
         [ 1.0195, -1.7280, -0.7840,  ..., -0.6917, -1.0280, -4.4956],
         ...,
         [-0.6214, -0.2852,  1.7707,  ...,  2.7852, -3.7889,  3.8231],
         [-2.1487, -0.1724, -1.4820,  ..., -0.6599, -3.5359, -1.4935],
         [ 3.3143,  7.4755,  6.0044,  ...,  1.4933,  2.1063,  1.2494]],

        [[ 2.8270,  2.3753,  1.2797,  ..., -0.2340, -0.4546, -0.6383],
         [ 2.5325, -3.7103,  3.2220,  ...,  3.1175,  6.9380,  6.2798],
         [-0.6357,  0.5668, -0.5201,  ..., -2.9405, -2.1435, -0.1453],
         ...,
         [-1.9567, -2.1103,  5.1930,  ...,  2.3184,  2.8593,  3.7591],
         [-4.1191, -4.2879, -0.5205,  ..., -2.4602, -0.2380, -3.9242],
         [ 2.7248,  5.6050,  5.8742,  ...,  2.3679,  5.7678, -0.4629]],

        [[ 6.9108,  4.6690,  0.8602,  ...,  0.3943, -0.6130,  2.2418],
         [-5.3005,  0.8046,  2.4068,  ...,  7.2282,  1.2845,  3.8773],
         [ 1.5311, -0.3033, -3.0165,  ..., -2.8416, -1.5927, -1.6260],
         ...,
         [-1.3866,  5.2433,  2.4691,  ...,  4.4579, -0.0222,  2.0831],
         [-7.7623, -4.1895, -1.9385,  ..., -6.1531, -3.0811, -3.5439],
         [ 3.6149,  8.3430,  2.6032,  ..., -0.8479, -1.5422, -0.3325]]],
       grad_fn=<SplitBackward0>), tensor([[[ -3.2474,   0.7684,  -2.9620,  ...,  -1.9998,  -2.1503,  -2.2109],
         [ -8.6326,  -8.7986,  -6.9958,  ...,  -6.4672,  -3.9656,  -8.5598],
         [  0.9600,   5.1366,   3.1696,  ...,  -3.9593,  -1.9332,  -4.5185],
         ...,
         [ -1.1687,  -1.2255,  -0.8962,  ...,  -8.2702,  -6.6058,  -5.8187],
         [  3.7514,   6.7865,   3.6962,  ...,   7.4874,   5.7117,   7.0364],
         [  5.4666,   4.6616,   4.1089,  ...,   3.1697,   4.6726,   4.4799]],

        [[ -6.5361,   0.8638,  -4.5531,  ...,  -4.8106,  -3.7357,  -4.4675],
         [ -6.0971,  -6.3744,  -4.8980,  ...,  -3.1805,  -8.0747,  -8.3054],
         [  5.1801,   4.0298,  -1.0421,  ...,  -6.3264,  -4.0083,  -5.3892],
         ...,
         [ -1.9711,  -0.0570,  -0.6116,  ...,  -6.0490,  -7.1546,  -5.9680],
         [  0.6668,   0.8315,   3.9275,  ...,   7.4372,   6.0557,   7.9588],
         [  6.6702,   5.6826,   4.2047,  ...,  -0.0359,   3.2255,   4.4390]],

        [[ -4.5300,   2.6306,   2.6365,  ...,  -1.3812,  -1.2061,  -2.6440],
         [ -6.8341,  -6.5182,  -3.3856,  ...,  -2.8321,  -7.0880,  -4.2246],
         [  4.8193,   6.0308,   2.8740,  ...,  -4.3247,   0.8498,  -6.2221],
         ...,
         [ -0.6130,  -3.6778,  -2.6402,  ...,  -5.6645,  -5.5898,  -5.9926],
         [  1.9995,   3.6680,  -2.0894,  ...,   9.5519,   7.2370,   9.6666],
         [  8.8911,   6.2619,   6.8016,  ...,   3.7196,   4.5407,   6.4383]],

        ...,

        [[ -6.9230,  -2.9442,   2.2833,  ...,  -1.4865,  -5.1906,  -2.6537],
         [ -7.6379,  -4.2704,  -7.4992,  ...,  -5.2165,  -6.6485,  -4.4945],
         [  3.0468,   2.2996,   2.1286,  ...,  -1.2650,  -0.9488,  -3.2184],
         ...,
         [ -2.6398,  -1.6927,   0.4636,  ...,  -7.7415,  -3.7914,  -7.4563],
         [  1.2296,   2.1240,   0.8609,  ...,   8.8584,   8.3322,   7.2435],
         [  5.1170,   5.4224,   2.9072,  ...,   1.2137,   1.8997,   2.8715]],

        [[ -0.4773,   1.2709,  -0.5905,  ...,  -3.9513,  -2.9440,  -5.1217],
         [ -6.2584,  -7.4465,  -5.9747,  ...,  -3.4214, -10.8864,  -7.6848],
         [  4.0800,   2.1662,   2.2305,  ...,  -3.8692,  -1.1220,  -4.4464],
         ...,
         [ -4.3956,  -2.9577,  -5.1694,  ...,  -5.6678,  -5.1115,  -6.2201],
         [ -1.1788,   0.7529,   5.6029,  ...,   5.5293,   7.0733,   6.6274],
         [  6.8921,   1.5100,   8.3373,  ...,   2.0385,   3.1489,   2.6819]],

        [[ -0.9000,  -1.0327,   1.0567,  ...,  -3.3204,  -1.0463,  -3.1133],
         [ -2.2895,  -8.2406,  -6.6239,  ...,  -8.1167,  -5.7143,  -7.7345],
         [  6.3120,   4.6387,  -0.3328,  ...,  -0.1479,  -2.2360,  -6.0263],
         ...,
         [ -1.8340,   2.1111,  -2.0678,  ...,  -4.9223,  -7.1447,  -4.1186],
         [  1.5520,   4.1063,   4.2940,  ...,   9.6750,   4.4663,   6.5932],
         [  7.7871,   6.8606,   6.0962,  ...,   4.1713,   3.7181,   6.3052]]],
       grad_fn=<SplitBackward0>))
after 1x1 Conv mask) torch.Size([8, 512, 124])
torch.Size([8, 1000])